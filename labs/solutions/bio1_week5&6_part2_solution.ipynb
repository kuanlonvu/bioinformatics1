{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 5 - Biological Databases - Protein-Protein Interactions & Pathways\n",
    "- October 2023\n",
    "- [https://https://github.com/tisimpson/bioinformatics1](https://github.com/tisimpson/bioinformatics1)\n",
    "- [ian.simpson@ed.ac.uk](mailto:ian.simpson@ed.ac.uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib as ul\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching KEGG pathway data\n",
    "\n",
    "human_pathways = pd.read_csv(ul.request.urlopen('http://rest.kegg.jp/list/pathway/hsa'),sep='\\t',header=0,names=['kegg_id','pathway_name'])\n",
    "\n",
    "human_pathways.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the KEGG ID for the pathway we're interested in\n",
    "# we're looking for \"Cell adhesion moelcules\"\n",
    "\n",
    "pathway_id = human_pathways[human_pathways['pathway_name'].str.match('Cell adhesion molecules')]['kegg_id']\n",
    "print(pathway_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can use the KEGG API to fetch the pathway data\n",
    "# pull the pathway entry from KEGG\n",
    "\n",
    "ul.request.urlretrieve('http://rest.kegg.jp/get/'+pathway_id.to_numpy()[0],'../data/pathways/cams.txt')\n",
    "\n",
    "# why not open this file and look at the contents. You will see the full pathway details including the gene names\n",
    "\n",
    "# open the file\n",
    "dop_file = open('../data/pathways/cams.txt','r')\n",
    "\n",
    "# I wanted to show you some basic python parsing and a simple for loop with a conditional in to demonstrate how you can quickly build simple parsers.\n",
    "# There are quicker ways to do this, but this is a good learning example.\n",
    "\n",
    "# set a flag for our parser, we will use this to know when we are in the gene section of the file\n",
    "flag=0\n",
    "\n",
    "# create a list to hold the genes\n",
    "genes = []\n",
    "\n",
    "# work through the text file one line at a time\n",
    "# notice we're pulling the line information so not just the gene id but also the description\n",
    "for line in dop_file:\n",
    "    # find the start of the gene entries\n",
    "    if 'GENE' in line:\n",
    "        # add the first gene to the list\n",
    "        genes.append(pd.Series(line.strip('GENE').strip().split('  ')))\n",
    "        # set the flag to 1, we are in the gene section of the file\n",
    "        flag = 1\n",
    "    # stop when we reach the end of the section and escape the file\n",
    "    elif 'REFERENCE' in line:\n",
    "        break\n",
    "    # continue adding the genes to the list\n",
    "    elif flag == 1:\n",
    "        genes.append(pd.Series(line.strip().split('  ',2)))\n",
    "\n",
    "# close the file\n",
    "dop_file.close()\n",
    "\n",
    "# convert the list to a dataframe\n",
    "dop_df = pd.DataFrame(genes)\n",
    "\n",
    "# name the columns\n",
    "dop_df.columns = ['gene_id','description']\n",
    "\n",
    "# you now have the gene_ids (NCBI Entrez GeneIDs for the genes in the pathway)\n",
    "print('The Cell Adhesion Moelcule Map has '+str(dop_df.shape[0])+' genes in it.\\n')\n",
    "\n",
    "# show the gene_ids\n",
    "print(dop_df['gene_id'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out a simple gene_id file\n",
    "\n",
    "f = open('../data/pathways/cams_geneids.txt','w')\n",
    "\n",
    "for i in dop_df['gene_id']:\n",
    "     f.write(i+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print this out in a nice table\n",
    "\n",
    "import prettytable as pt\n",
    "\n",
    "# create a pretty table object\n",
    "table = pt.PrettyTable()\n",
    "\n",
    "# add the columns\n",
    "table.add_column('Gene ID',dop_df['gene_id'].to_numpy())\n",
    "table.add_column('Description',dop_df['description'].to_numpy())\n",
    "\n",
    "# print out the table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could go on to use this basic file of gene ids to retreive protein interaction data from BioGrid or Intact. We will do this in the week6 lab using APIs.\n",
    "\n",
    "# you could have a look at one of the most commonly used protein-protein interaction databases in advance if you like:\n",
    "#   STRING - https://string-db.org/ or BIOGRID - https://thebiogrid.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating Retrieval of Protein-Protein Interactions from STRING\n",
    "\n",
    "The details of the String-DB API can be found here - [https://string-db.org/help/api/](https://string-db.org/help/api/)\n",
    "\n",
    "APIs have specific formats required for their query URLs and it getting these correct in your code can take a little time until you get used to them. In this case we need to concatenate (stitch together) our gene IDs using a '%0D' string. This is actually the encoding for a line-return which is in effect mimicking the one gene per line entry that you would paste into the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a concatenated list of entrezIDs as strings\n",
    "# note we are taking integer gene_ids from the 'gene_id' column of the dataframe we generated above then using\n",
    "# the map function to convert each one into a string. The join function then concatenates them using the '%0D' string\n",
    "# to stitch them all together. This string will be used to help us build the API query URL.\n",
    "entrezIDs = '%0D'.join(map(str,dop_df['gene_id']))\n",
    "\n",
    "# pass the list of EntrezIDs to the String-DB API return the String-IDs\n",
    "# we first form the query url using the 'get_string_ids' API function which takes a list of identifiers and\n",
    "# converts them into the internal String-DB accession IDs. This massively speeds up the search and allows us to\n",
    "# search for more than 10 at once which is an API restriction for other API functions if String-DB internal accessions \n",
    "# aren't used.\n",
    "query_url = 'https://string-db.org/api/tsv-no-header/get_string_ids?identifiers='+entrezIDs+'&species=9606&format=only-ids'\n",
    "\n",
    "# use the urllib library to retrieve the String-DB internal IDs\n",
    "result = ul.request.urlopen(query_url).read().decode('utf-8')\n",
    "\n",
    "# now we want to query String-DB to retrieve interactions from this list of String-DB IDs\n",
    "# we create a concatenated list of stringdbIDs in much the same way as above for the Entrez Gene IDs\n",
    "stringdbIDs = '%0D'.join(result.splitlines())\n",
    "\n",
    "# again we build the query for interactions using the String-DB IDs\n",
    "query_url = 'https://string-db.org/api/tsv/network?identifiers='+stringdbIDs+'&species=9606'\n",
    "\n",
    "# again using urllib to retrieve the interactions these are returned in a standard tab delimied text format\n",
    "interactions = ul.request.urlopen(query_url).read().decode('utf-8').splitlines()\n",
    "\n",
    "# we need to split the result by these 'tabs' (\\t - is used to identfy them)\n",
    "int_test = [interaction.split('\\t') for interaction in interactions]\n",
    "\n",
    "# we extract the field names from the first row\n",
    "column_names = int_test[:1][0]\n",
    "\n",
    "# create a Pandas dataframe of the interaction data we have just retrieved from String-DB\n",
    "interactions_df = pd.DataFrame(int_test,columns=column_names)\n",
    "\n",
    "# delete the first row that held the fieldnames but we no longer need\n",
    "interactions_df = interactions_df.drop(labels=0,axis=0)\n",
    "\n",
    "# remove any duplicate rows\n",
    "final_interactions = interactions_df.drop_duplicates()\n",
    "\n",
    "# show the top of the protein-protein interaction table\n",
    "final_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple network view of the interactions using the NetworkX library\n",
    "# https://networkx.org/documentation/stable/index.html\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check the column names of the dataframe\n",
    "print(final_interactions.columns)\n",
    "\n",
    " #Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# add all nodes\n",
    "G.add_nodes_from(set(final_interactions['preferredName_A']) | set(final_interactions['preferredName_B'])) \n",
    "\n",
    "# add the edges (connections) to the network\n",
    "edges = []\n",
    "for edge1 , edge2  in zip(final_interactions['preferredName_A'] , final_interactions['preferredName_B']) : #add all edge to the network\n",
    "    edges.append((edge1 , edge2 ))\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# draw the network with a force directed layout specify plot size and node size and thin light gray edges\n",
    "plt.figure(figsize=(15,15))\n",
    "nx.draw(G, pos=nx.spring_layout(G,k=2), with_labels=True,node_size=100,edge_color='gray',node_color='lightblue',width=0.5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3780209f5c547b790e301ddcf82da1791fd2d3a86603b11e6f996468095ce25a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
